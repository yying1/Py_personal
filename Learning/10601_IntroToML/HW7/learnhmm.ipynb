{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b86670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import sys\n",
    "from utils import make_dict, parse_file\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f369299a",
   "metadata": {},
   "source": [
    "python learnhmm.py toy_data/train.txt toy_data/index_to_word.txt toy_data/index_to_tag.txt toy_data/hmminit1.txt toy_data/hmmemit1.txt toy_data/hmmtrans1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17fb15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('train_input', type=str,help='path to training input .txt file')\n",
    "parser.add_argument('index_to_word', type=str,help='path to index_to_word.txt file')\n",
    "parser.add_argument('index_to_tag', type=str,help='path to index_to_tag.txt file')\n",
    "parser.add_argument('init', type=str,help='path to store the hmm_init.txt (pi) file')\n",
    "parser.add_argument('emission', type=str,help='path to store the hmm_emission.txt (A) file')\n",
    "parser.add_argument('transition', type=str, help='path to store the hmm_transition.txt (B) file')\n",
    "parser.add_argument('--debug', type=bool, default=True,help='set to True to show logging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9658b6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.train_input = \"toy_data/train.txt\"\n",
    "parser.index_to_word = \"toy_data/index_to_word.txt\"\n",
    "parser.index_to_tag = \"toy_data/index_to_tag.txt\"\n",
    "parser.init = \"toy_data/hmminit.txt\"\n",
    "parser.emission = \"toy_data/hmmemit.txt\"\n",
    "parser.transition = \"toy_data/hmmtrans.txt\"\n",
    "logging.basicConfig(format='[%(asctime)s] {%(pathname)s:%(funcName)s:%(lineno)04d} %(levelname)s - %(message)s', datefmt=\"%H:%M:%S\",level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51329c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: You might find it useful to define functions that do the following:\n",
    "# 1. Calculate the init matrix\n",
    "# 2. Calculate the emission matrix\n",
    "# 3. Calculate the transition matrix\n",
    "# 4. Normalize the matrices appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47889cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser\n",
    "word_dict = make_dict(args.index_to_word)\n",
    "tag_dict = make_dict(args.index_to_tag)\n",
    "# Parse the train file\n",
    "# Suggestion: Take a minute to look at the training file,\n",
    "# it always hels to know your data :)\n",
    "sentences, tags = parse_file(args.train_input)\n",
    "logging.debug(f\"Num Sentences: {len(sentences)}\")\n",
    "logging.debug(f\"Num Tags: {len(tags)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e319df82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_init(tags,tag_dict):\n",
    "    first_word = np.array([x[0] for x in tags],dtype='object')\n",
    "    uniqueValues, occurCount = np.unique(first_word, return_counts=True)\n",
    "    init = np.empty((len(tag_dict),1), dtype='float')\n",
    "    total_pseudo = len(tag_dict)+len(first_word)\n",
    "    for i in range(len(tag_dict)):\n",
    "        tag = list(tag_dict.keys())[i]\n",
    "        if tag not in uniqueValues:\n",
    "            init[tag_dict[tag],0] = 1.0 /total_pseudo\n",
    "        else:\n",
    "            tag_index = np.where(uniqueValues == tag)\n",
    "            init[tag_dict[tag],0] = (1.0+occurCount[tag_index]) /total_pseudo\n",
    "    return init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2d1471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_emi(tags,tag_dict,word_dict,sentences):\n",
    "    emi = np.empty((len(tag_dict),len(word_dict)), dtype='float')\n",
    "    for i in range(len(tag_dict)):\n",
    "        tag = list(tag_dict.keys())[i]\n",
    "        word_count = dict.fromkeys(word_dict.keys(),0)\n",
    "        for t in range(len(tags)):\n",
    "            match_tag_index = [i for i,x in enumerate(tags[t]) if x == tag]\n",
    "            if len(match_tag_index) != 0:\n",
    "                for m in match_tag_index:\n",
    "                    word_count[sentences[t][m]]+=1\n",
    "        for word in word_dict.keys():\n",
    "            emi[i][word_dict[word]] = (word_count[word]+1.0)/(sum(word_count.values())+len(word_dict))\n",
    "    return emi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba8c1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "emi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5648c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_dict)\n",
    "print(sentences)\n",
    "print(tags)\n",
    "print(tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4f6b988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tra(tags,tag_dict):\n",
    "    tra = np.empty((len(tag_dict),len(tag_dict)), dtype='float')\n",
    "    for i in range(len(tag_dict)):\n",
    "        tag_s = list(tag_dict.keys())[i]\n",
    "        tag_count_dict = dict.fromkeys(tag_dict.keys(),0)\n",
    "        for tag in tags:\n",
    "            match_tag_index = [i for i,x in enumerate(tag) if x == tag_s and i < len(tag)-1]\n",
    "            for m in match_tag_index:\n",
    "                tag_count_dict[tag[m+1]]+=1\n",
    "        for tag in tag_count_dict.keys():\n",
    "            tra[i][tag_dict[tag]] = (tag_count_dict[tag]+1.0)/(sum(tag_count_dict.values())+len(tag_dict))\n",
    "    return tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcca6699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for emprical\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('train_input', type=str,help='path to training input .txt file')\n",
    "parser.add_argument('index_to_word', type=str,help='path to index_to_word.txt file')\n",
    "parser.add_argument('index_to_tag', type=str,help='path to index_to_tag.txt file')\n",
    "parser.add_argument('init', type=str,help='path to store the hmm_init.txt (pi) file')\n",
    "parser.add_argument('emission', type=str,help='path to store the hmm_emission.txt (A) file')\n",
    "parser.add_argument('transition', type=str, help='path to store the hmm_transition.txt (B) file')\n",
    "parser.add_argument('--debug', type=bool, default=True,help='set to True to show logging')\n",
    "parser.train_input = \"en_data/train.txt\"\n",
    "parser.index_to_word = \"en_data/index_to_word.txt\"\n",
    "parser.index_to_tag = \"en_data/index_to_tag.txt\"\n",
    "args = parser\n",
    "word_dict = make_dict(args.index_to_word)\n",
    "tag_dict = make_dict(args.index_to_tag)\n",
    "for i in [100,1000,10000]:\n",
    "    sentences, tags = parse_file(args.train_input)\n",
    "    sentences = sentences[:i]\n",
    "    tags = tags[:i]\n",
    "    # Train your HMM\n",
    "    init = build_init(tags,tag_dict) # TODO: Construct your init matrix\n",
    "    emission = build_emi(tags,tag_dict,word_dict,sentences) # TODO: Construct your emission matrix\n",
    "    transition = build_tra(tags,tag_dict) # TODO: Construct your transition matrix\n",
    "\n",
    "    parser.init = \"en_data/hmminit\"+\"_\"+str(i)+\".txt\"\n",
    "    parser.emission = \"en_data/hmmemit\"+\"_\"+str(i)+\".txt\"\n",
    "    parser.transition = \"en_data/hmmtrans\"+\"_\"+str(i)+\".txt\"\n",
    "    args = parser\n",
    "    np.savetxt(args.init, init)\n",
    "    np.savetxt(args.emission, emission)\n",
    "    np.savetxt(args.transition, transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2214add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    # Get the dictionaries\n",
    "    word_dict = make_dict(args.index_to_word)\n",
    "    tag_dict = make_dict(args.index_to_tag)\n",
    "\n",
    "    # Parse the train file\n",
    "    # Suggestion: Take a minute to look at the training file,\n",
    "    # it always hels to know your data :)\n",
    "    sentences, tags = parse_file(args.train_input)\n",
    "    logging.debug(f\"Num Sentences: {len(sentences)}\")\n",
    "    logging.debug(f\"Num Tags: {len(tags)}\")\n",
    "    \n",
    "    # Train your HMM\n",
    "    init = build_init(tags,tag_dict) # TODO: Construct your init matrix\n",
    "    emission = build_emi(tags,tag_dict,word_dict,sentences) # TODO: Construct your emission matrix\n",
    "    transition = build_tra(tags,tag_dict) # TODO: Construct your transition matrix\n",
    "\n",
    "    # Making sure we have the right shapes\n",
    "    logging.debug(f\"init matrix shape: {init.shape}\")\n",
    "    logging.debug(f\"emission matrix shape: {emission.shape}\")\n",
    "    logging.debug(f\"transition matrix shape: {transition.shape}\")\n",
    "\n",
    "    # Saving the files for inference\n",
    "    # We're doing this for you :)\n",
    "    # TODO: Just Uncomment the following lines when you're ready!\n",
    "    \n",
    "    np.savetxt(args.init, init)\n",
    "    np.savetxt(args.emission, emission)\n",
    "    np.savetxt(args.transition, transition)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e1142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to change anything beyond this point\n",
    "if __name__ == \"__main__\":\n",
    "    args = parser.parse_args()\n",
    "    if args.debug:\n",
    "        logging.basicConfig(format='[%(asctime)s] {%(pathname)s:%(funcName)s:%(lineno)04d} %(levelname)s - %(message)s',\n",
    "                            datefmt=\"%H:%M:%S\",\n",
    "                            level=logging.DEBUG)\n",
    "    logging.debug('*** Debugging Mode ***')\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
