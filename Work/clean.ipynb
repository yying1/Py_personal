{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "inflow=pd.read_excel('data.xlsx')\n",
    "def clean_part_number(attr):\n",
    "    attr_val=str(attr)\n",
    "    if len(str(attr))>40:\n",
    "        return ''\n",
    "    else:\n",
    "        return attr\n",
    "def clean_catalog_number(attr):\n",
    "    attr_val=str(attr)\n",
    "    if ';' in attr_val:\n",
    "        attr_list=attr_val.split(';')\n",
    "        attr_clean_value=attr_list[0]\n",
    "        return attr_clean_value\n",
    "def remove_url(attr):\n",
    "    attr_val=str(attr)\n",
    "    if 'http' or 'www' in attr_val.lower():\n",
    "        ret = re.compile(r'[http|https]*://[a-zA-Z0-9.?/&=:]*',re.S)\n",
    "        rep=re.compile(r'www.[a-zA-Z0-9.?/&=:]*',re.S)\n",
    "        attr_1=ret.sub(\"\",attr_val)\n",
    "        attr_2=rep.sub(\"\",attr_1)               \n",
    "        return attr_2\n",
    "def iter_invalid_set(attr):\n",
    "    attr_val=str(attr)\n",
    "    \n",
    "    for invalid in invalid_set:\n",
    "        invalid = str(invalid)\n",
    "        if invalid in attr_val:                \n",
    "            attr_val = attr_val.replace(invalid,'')\n",
    "    return attr_val\n",
    "inflow['part_number.value']=inflow['part_number.value'].apply(lambda x:clean_part_number(x))\n",
    "inflow['catalog_number.value']=inflow['catalog_number.value'].apply(lambda x:clean_catalog_number(x))\n",
    "# inflow['rtip_product_description.value']=inflow['rtip_product_description.value'].apply(lambda x:remove_url(x))\n",
    "\n",
    "invalid_df=pd.read_excel('invalid_character.xlsx',header=None)\n",
    "invalid_values = invalid_df[0].values\n",
    "invalid_set = set(invalid_values)\n",
    "urlattrs=[]\n",
    "for col in inflow.columns.tolist():\n",
    "    if 'rtip_product_description' or 'bullet_point' in str(col):\n",
    "        urlattrs.append(col)\n",
    "for urlattr in urlattrs:\n",
    "    inflow[urlattr]=inflow[urlattr].apply(lambda x:remove_url(x))\n",
    "    inflow[urlattr]=inflow[urlattr].apply(lambda x:iter_invalid_set(x))\n",
    "inflow.to_excel('inflow.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "inflow=pd.read_excel('data.xlsx')\n",
    "attr_list=['bullet_point','generic_keyword','subject_keyword']\n",
    "# attr_list=['bullet_point','generic_keyword']\n",
    "# def check_special_symbol(attr):\n",
    "#     invalid_value=invalid[0].tolist()\n",
    "# for attr in attr_list:\n",
    "dropattr=[]\n",
    "def mergeempty(inflow,attr):\n",
    "    \n",
    "    newattr=[]\n",
    "\n",
    "    for col in inflow.columns.tolist():\n",
    "        if str(attr) in str(col):\n",
    "            newattr.append(col)\n",
    "    #     if newattr=[]:\n",
    "    #         pass\n",
    "    #     else:\n",
    "    #         return mergeempty\n",
    "    def clearem(d):\n",
    "        while '' in d:\n",
    "            d.remove('')\n",
    "        return d\n",
    "    line=[]\n",
    "    newattr2=newattr\n",
    "    newattr2.insert(0,'asin')\n",
    "    attr_inflow=inflow[newattr2].fillna('')\n",
    "    for x in attr_inflow.index:\n",
    "        out=clearem(attr_inflow.loc[x].tolist())\n",
    "        line.append(out)\n",
    "    line_df=pd.DataFrame(line)\n",
    "\n",
    "    colus=line_df.columns.tolist()\n",
    "    newname=['ASIN',attr+'.value']\n",
    "    try:\n",
    "        colus=colus[2:]\n",
    "        for n in colus:\n",
    "            n=attr+'#'+str(int(n))+'.value'\n",
    "            newname.append(n)\n",
    "        line_df.columns=newname\n",
    "    except:\n",
    "        pass\n",
    "    return line_df,newattr\n",
    "result_all=[]\n",
    "# attr_clean=inflow[['asin']]\n",
    "# attr_clean.rename(columns={\"asin\":\"ASIN\"},inplace=True)\n",
    "attr_count=0\n",
    "for attr in attr_list:   \n",
    "    attr_count=attr_count+1\n",
    "    mergeempty(inflow,attr)\n",
    "    result=mergeempty(inflow,attr)[1]\n",
    "    no_empty=mergeempty(inflow,attr)[0]\n",
    "    if mergeempty(inflow,attr)[1]==[]:\n",
    "        pass\n",
    "    else:   \n",
    "        result.pop(0)\n",
    "        result_all.append(result)\n",
    "        if attr_count==1:\n",
    "            attr_clean=no_empty\n",
    "        else:   \n",
    "            attr_clean=pd.concat([attr_clean,no_empty],axis=1)\n",
    "        result=[]\n",
    "        newattr=[]\n",
    "\n",
    "# mergeempty(inflow,'subject_keyword').to_excel(r'result_merge_list.xlsx',index=False)\n",
    "attr_clean.to_excel('result_merge_list.xlsx',index=False)\n",
    "# result_all.to_excel('attr_list.xlsx',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
